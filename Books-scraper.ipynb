{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pickle\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Start WebDriver session\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Load Goodreads\n",
    "driver.get(\"https://www.goodreads.com\")\n",
    "\n",
    "# Load saved cookies for authentication\n",
    "try:\n",
    "    with open(\"cookies.pkl\", \"rb\") as file:\n",
    "        cookies = pickle.load(file)\n",
    "        for cookie in cookies:\n",
    "            driver.add_cookie(cookie)\n",
    "    print(\"‚úÖ Cookies loaded successfully!\")\n",
    "    driver.refresh()\n",
    "    time.sleep(3)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Cookie file not found. Login required.\")\n",
    "\n",
    "# Extract book URLs from Goodreads list\n",
    "goodreads_list_url = \"https://www.goodreads.com/list/show/312.Best_Humorous_Books\"\n",
    "driver.get(goodreads_list_url)\n",
    "time.sleep(5)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "book_urls = []\n",
    "seen_urls = set()\n",
    "\n",
    "for book in soup.select(\"a.bookTitle\"):\n",
    "    book_url = \"https://www.goodreads.com\" + book[\"href\"]\n",
    "    if book_url not in seen_urls:\n",
    "        book_urls.append(book_url)\n",
    "        seen_urls.add(book_url)\n",
    "    if len(book_urls) >= 10:  # Stop after collecting 10 unique books\n",
    "        break\n",
    "\n",
    "print(f\"üîç Extracted {len(book_urls)} book URLs from the list.\")\n",
    "\n",
    "# Open CSV file for saving data\n",
    "with open(\"Best_Humorous_Books.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\n",
    "        \"Book Name\", \"Image\", \"Book Format\", \"Published Date\", \n",
    "        \"Number of Pages\", \"Language\", \"Authors\", \"Rating\", \n",
    "        \"Rating Count\", \"Review Count\", \"Genres\", \"ASIN\", \"Publisher\", \"ISBN-13\", \n",
    "        \"Amazon Affiliate Link\", \"Google Books Preview Link\"\n",
    "    ])\n",
    "\n",
    "    # Loop through Goodreads book URLs\n",
    "    for full_url in book_urls:\n",
    "        driver.get(full_url)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # **Hover over the section to reveal the button**\n",
    "        try:\n",
    "            book_details_section = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"BookDetails\"))\n",
    "            )\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(book_details_section).perform()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Could not find book details section.\")\n",
    "\n",
    "        # **Click the 'Book details & editions' button**\n",
    "        try:\n",
    "            button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(@aria-label, 'Book details and editions')]\"))\n",
    "            )\n",
    "            button.click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Could not find or click the 'Book details & editions' button.\")\n",
    "\n",
    "        # Extract book details\n",
    "        try:\n",
    "            published_date = driver.find_element(By.CSS_SELECTOR, \"p[data-testid='publicationInfo']\").text.strip()\n",
    "        except:\n",
    "            published_date = \"N/A\"\n",
    "\n",
    "        # **Extract Data from JSON-LD (Metadata in Page Source)**\n",
    "        book_name, image, book_format, number_of_pages, in_language_json = \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\"\n",
    "        person_names, rating_value, rating_count, review_count, genres = \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\"\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            script_tag = soup.find(\"script\", type=\"application/ld+json\")\n",
    "\n",
    "            if script_tag:\n",
    "                data = json.loads(script_tag.string)\n",
    "                book_name = data.get(\"name\", \"N/A\")\n",
    "                image = data.get(\"image\", \"N/A\")\n",
    "                book_format = data.get(\"bookFormat\", \"N/A\")\n",
    "                number_of_pages = data.get(\"numberOfPages\", \"N/A\")\n",
    "                in_language_json = data.get(\"inLanguage\", \"N/A\")\n",
    "\n",
    "                authors = data.get(\"author\", [])\n",
    "                person_names = \", \".join([person.get(\"name\", \"N/A\") for person in authors]) if isinstance(authors, list) else authors.get(\"name\", \"N/A\")\n",
    "\n",
    "                aggregate_rating = data.get(\"aggregateRating\", {})\n",
    "                rating_value = aggregate_rating.get(\"ratingValue\", \"N/A\")\n",
    "                rating_count = aggregate_rating.get(\"ratingCount\", \"N/A\")\n",
    "                review_count = aggregate_rating.get(\"reviewCount\", \"N/A\")\n",
    "\n",
    "            # Extract genres\n",
    "            genre_tags = soup.select(\"a[href*='/genres/']\")\n",
    "            genres = \", \".join([genre.text.strip() for genre in genre_tags]) if genre_tags else \"N/A\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error extracting JSON-LD data: {e}\")\n",
    "\n",
    "        # **Extract ASIN, Publisher, and ISBN-13**\n",
    "        asin, publisher, isbn13 = \"N/A\", \"N/A\", \"N/A\"\n",
    "\n",
    "        try:\n",
    "            script_tags = soup.find_all(\"script\", type=\"application/json\")\n",
    "\n",
    "            for script in script_tags:\n",
    "                json_data = json.loads(script.string)\n",
    "                \n",
    "                if isinstance(json_data, dict):\n",
    "                    book_details = json_data.get(\"props\", {}).get(\"pageProps\", {}).get(\"apolloState\", {})\n",
    "                    \n",
    "                    for key in book_details:\n",
    "                        if key.startswith(\"Book:\"):\n",
    "                            book = book_details[key]\n",
    "                            asin = book.get(\"details\", {}).get(\"asin\", \"N/A\")\n",
    "                            publisher = book.get(\"details\", {}).get(\"publisher\", \"N/A\")\n",
    "                            isbn13 = book.get(\"details\", {}).get(\"isbn13\", \"N/A\")\n",
    "                            break  # Exit loop once book data is found\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error extracting ASIN, Publisher, and ISBN-13: {e}\")\n",
    "\n",
    "        # **Generate Amazon Affiliate Link**\n",
    "        if asin != \"N/A\":\n",
    "            amazon_affiliate_link = f\"https://www.amazon.in/dp/{asin}/ref=nosim?tag=thopdev-21\"\n",
    "        else:\n",
    "            amazon_affiliate_link = \"N/A\"\n",
    "\n",
    "        # **Find Google Books Preview Link**\n",
    "        google_books_preview_link = \"N/A\"\n",
    "        if isbn13 != \"N/A\":\n",
    "            google_books_api_url = f\"https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn13}\"\n",
    "            try:\n",
    "                response = requests.get(google_books_api_url)\n",
    "                data = response.json()\n",
    "                if \"items\" in data and len(data[\"items\"]) > 0:\n",
    "                    volume_id = data[\"items\"][0][\"id\"]\n",
    "                    google_books_preview_link = f\"https://www.google.co.in/books/edition/_/{volume_id}?hl=en&gbpv=1\"\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error fetching Google Books preview link: {e}\")\n",
    "\n",
    "        # Save data to CSV (Ensure ASIN & ISBN-13 are stored as text to keep leading zeros)\n",
    "        writer.writerow([\n",
    "            book_name, image, book_format, published_date, \n",
    "            number_of_pages, in_language_json, person_names, \n",
    "            rating_value, rating_count, review_count, genres, \n",
    "            f\"'{asin}\", publisher, f\"'{isbn13}\", amazon_affiliate_link, google_books_preview_link\n",
    "        ])\n",
    "        print(f\"‚úÖ Scraped: {book_name} | ASIN: {asin} | ISBN-13: {isbn13} | Amazon Link: {amazon_affiliate_link} | Google Books: {google_books_preview_link}\")\n",
    "\n",
    "# Close WebDriver\n",
    "driver.quit()\n",
    "print(\"üöÄ Task completed! All book details saved in 'Best_Humorous_Books.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
